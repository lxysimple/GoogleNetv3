{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropy:0.11191823333501816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "output = torch.tensor([[4.0, 5.0, 10.0], [1.0, 5.0, 4.0], [1.0, 15.0, 4.0]])\n",
    "label = torch.tensor([2, 1, 1], dtype=torch.int64)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, label)\n",
    "\n",
    "print(\"CrossEntropy:{}\".format(loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签平滑后的损失函数公式\n",
    "<img src=\"./imgs/lsr_formula1.png\"  width=\"500\" height=\"300\" align=\"bottom\" />\n",
    "\n",
    "其中q是one-hot向量，eg： q = （0， 0， 1）    \n",
    "u是均匀分布， eg：u = (1/3, 1/3, 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵计算公式\n",
    " $H(q, p) = - \\sum^{K}_{k = 1}{log p_i \\cdot q_i } = -(0*log p_1 + 0*log p_2 + 1*log p_3) =- log p_3$    (假设  q = （0， 0， 1）)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $H(u, p) = - \\sum^{K}_{k = 1}{log p_i \\cdot u_i } = - \\sum^{K}_{k = 1}{log p_i \\cdot \\frac{1}{K}}$ \n",
    " $= - \\frac{1}{K}\\sum^{K}_{k = 1}{log p_i } = - \\frac{\\sum^{K}_{k = 1}{log p_i}}{K} = - \\frac{log p_1 + log p_2 + log p_3}{3} $   (假设 K=3, u = （1/3， 1/3， 1/3）) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: tensor([[2],\n",
      "        [1],\n",
      "        [1]]) torch.Size([3, 1])\n",
      "log_probs:  tensor([[-6.0092e+00, -5.0092e+00, -9.1745e-03],\n",
      "        [-4.3266e+00, -3.2656e-01, -1.3266e+00],\n",
      "        [-1.4000e+01, -1.7524e-05, -1.1000e+01]]) torch.Size([3, 3])\n",
      "H_qp:  tensor([[9.1745e-03],\n",
      "        [3.2656e-01],\n",
      "        [1.7524e-05]]) torch.Size([3, 1])\n",
      "CrossEntropy:0.11191823333501816\n",
      "LableSmoothingCrossEntropy:0.11647378653287888\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, eps=0.001):\n",
    "\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        # CE(q, p) = - sigma(q_i * log(p_i))\n",
    "        log_probs = torch.nn.functional.log_softmax(x, dim=-1)  # 实现  log(p_i)  \n",
    "\n",
    "        # H(q, p)\n",
    "        H_qp = -log_probs.gather(index=target.unsqueeze(1), dim=-1)  # 只需要q_i == 1的地方， 此时已经得到CE\n",
    "        print(\"index:\" , target.unsqueeze(1), target.unsqueeze(1).shape,)\n",
    "        print(\"log_probs: \", log_probs, log_probs.shape)\n",
    "        print(\"H_qp: \", H_qp, H_qp.shape)\n",
    "        H_qp = H_qp.squeeze(1)  \n",
    "        \n",
    "        # H(u, p)\n",
    "        H_uq = -log_probs.mean()  # 由于u是均匀分布，等价于求均值\n",
    "                                                \n",
    "        loss = (1-self.eps) * H_qp + self.eps * H_uq\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "    \n",
    "criterion = LabelSmoothingCrossEntropy(eps=0.001)\n",
    "loss_ls = criterion(output, label)\n",
    "\n",
    "print(\"CrossEntropy:{}\".format(loss))\n",
    "print(\"LableSmoothingCrossEntropy:{}\".format(loss_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数1：torch.nn.functional.log_softmax\n",
    "### torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
    "功能：先进行softmax激活函数，再取对数\n",
    "<img src=\"./imgs/log_softmax.png\" width=\"500\" height=\"300\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数2：torch.gather\n",
    "### torch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor\n",
    "按给定的轴，根据index在input上收集数据\n",
    "```python\n",
    "out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0    \n",
    "out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1    \n",
    "out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.tensor([[1,2],[3,4]])\n",
    "torch.gather(inputs, dim=1, index=torch.tensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.4_gpu",
   "language": "python",
   "name": "pytorch_1.4_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
